{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15ad9ed-75a2-4fcb-84e4-26c63c0316fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 13:20:36.852378: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-25 13:20:37.651567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-06-25 13:20:37.651637: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-06-25 13:20:37.651642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from scipy import interp\n",
    "from tensorflow.keras.layers import Embedding, Dense \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49615554-9ecb-435c-b09a-75600d0dcadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1...\n",
      " Fold 1 metrics: {'fold': 1, 'accuracy': 0.4444444444444444, 'roc_auc': 0.5555555555555556, 'avg_precision': 0.5846920055253388, 'precision': 0.4, 'recall': 0.2222222222222222, 'f1': 0.2857142857142857}\n",
      "Evaluating fold 2...\n",
      " Fold 2 metrics: {'fold': 2, 'accuracy': 0.6111111111111112, 'roc_auc': 0.654320987654321, 'avg_precision': 0.7636094841977195, 'precision': 0.625, 'recall': 0.5555555555555556, 'f1': 0.5882352941176471}\n",
      "Evaluating fold 3...\n",
      " Fold 3 metrics: {'fold': 3, 'accuracy': 0.6111111111111112, 'roc_auc': 0.6419753086419753, 'avg_precision': 0.5767815517815518, 'precision': 0.6, 'recall': 0.6666666666666666, 'f1': 0.631578947368421}\n",
      "Evaluating fold 4...\n",
      " Fold 4 metrics: {'fold': 4, 'accuracy': 0.6470588235294118, 'roc_auc': 0.7638888888888888, 'avg_precision': 0.8468253968253969, 'precision': 0.7142857142857143, 'recall': 0.5555555555555556, 'f1': 0.6250000000000001}\n",
      "Evaluating fold 5...\n",
      " Fold 5 metrics: {'fold': 5, 'accuracy': 0.8235294117647058, 'roc_auc': 0.875, 'avg_precision': 0.8953093203093205, 'precision': 0.875, 'recall': 0.7777777777777778, 'f1': 0.823529411764706}\n",
      "Evaluating fold 6...\n",
      " Fold 6 metrics: {'fold': 6, 'accuracy': 0.7647058823529411, 'roc_auc': 0.8472222222222222, 'avg_precision': 0.8863025863025864, 'precision': 0.7272727272727273, 'recall': 0.8888888888888888, 'f1': 0.7999999999999999}\n",
      "Evaluating fold 7...\n",
      " Fold 7 metrics: {'fold': 7, 'accuracy': 0.47058823529411764, 'roc_auc': 0.4166666666666667, 'avg_precision': 0.48266856600189934, 'precision': 0.5, 'recall': 0.5555555555555556, 'f1': 0.5263157894736842}\n",
      "Evaluating fold 8...\n",
      " Fold 8 metrics: {'fold': 8, 'accuracy': 0.5294117647058824, 'roc_auc': 0.7083333333333333, 'avg_precision': 0.7413410663410664, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'f1': 0.5}\n",
      "Evaluating fold 9...\n",
      " Fold 9 metrics: {'fold': 9, 'accuracy': 0.7058823529411765, 'roc_auc': 0.6666666666666666, 'avg_precision': 0.6448953823953824, 'precision': 0.7, 'recall': 0.7777777777777778, 'f1': 0.7368421052631577}\n",
      "Evaluating fold 10...\n",
      " Fold 10 metrics: {'fold': 10, 'accuracy': 0.47058823529411764, 'roc_auc': 0.4722222222222222, 'avg_precision': 0.6159830365712717, 'precision': 0.5, 'recall': 0.4444444444444444, 'f1': 0.47058823529411764}\n",
      "Evaluating fold 11...\n",
      " Fold 11 metrics: {'fold': 11, 'accuracy': 0.5294117647058824, 'roc_auc': 0.5833333333333333, 'avg_precision': 0.6366682700016033, 'precision': 0.5555555555555556, 'recall': 0.5555555555555556, 'f1': 0.5555555555555556}\n",
      "Evaluating fold 12...\n",
      " Fold 12 metrics: {'fold': 12, 'accuracy': 0.6470588235294118, 'roc_auc': 0.6388888888888888, 'avg_precision': 0.725535113035113, 'precision': 0.6363636363636364, 'recall': 0.7777777777777778, 'f1': 0.7000000000000001}\n",
      "Evaluating fold 13...\n",
      " Fold 13 metrics: {'fold': 13, 'accuracy': 0.6470588235294118, 'roc_auc': 0.7916666666666666, 'avg_precision': 0.8790784832451499, 'precision': 0.6363636363636364, 'recall': 0.7777777777777778, 'f1': 0.7000000000000001}\n",
      "Evaluating fold 14...\n",
      " Fold 14 metrics: {'fold': 14, 'accuracy': 0.7058823529411765, 'roc_auc': 0.736111111111111, 'avg_precision': 0.759589947089947, 'precision': 0.8333333333333334, 'recall': 0.5555555555555556, 'f1': 0.6666666666666667}\n",
      "Evaluating fold 15...\n",
      " Fold 15 metrics: {'fold': 15, 'accuracy': 0.6470588235294118, 'roc_auc': 0.7777777777777778, 'avg_precision': 0.8176638176638178, 'precision': 0.6363636363636364, 'recall': 0.7777777777777778, 'f1': 0.7000000000000001}\n",
      "Evaluating fold 16...\n",
      " Fold 16 metrics: {'fold': 16, 'accuracy': 0.7647058823529411, 'roc_auc': 0.9027777777777778, 'avg_precision': 0.9280303030303032, 'precision': 0.8571428571428571, 'recall': 0.6666666666666666, 'f1': 0.75}\n",
      "Evaluating fold 17...\n",
      " Fold 17 metrics: {'fold': 17, 'accuracy': 0.6470588235294118, 'roc_auc': 0.8055555555555556, 'avg_precision': 0.8555555555555556, 'precision': 0.6363636363636364, 'recall': 0.7777777777777778, 'f1': 0.7000000000000001}\n",
      "Evaluating fold 18...\n",
      " Fold 18 metrics: {'fold': 18, 'accuracy': 0.6470588235294118, 'roc_auc': 0.6111111111111112, 'avg_precision': 0.5614898989898989, 'precision': 0.6, 'recall': 0.75, 'f1': 0.6666666666666665}\n",
      "Evaluating fold 19...\n",
      " Fold 19 metrics: {'fold': 19, 'accuracy': 0.6470588235294118, 'roc_auc': 0.7222222222222222, 'avg_precision': 0.7720508658008658, 'precision': 0.625, 'recall': 0.625, 'f1': 0.625}\n",
      "Evaluating fold 20...\n",
      " Fold 20 metrics: {'fold': 20, 'accuracy': 0.4117647058823529, 'roc_auc': 0.48611111111111116, 'avg_precision': 0.5882478632478633, 'precision': 0.375, 'recall': 0.375, 'f1': 0.375}\n",
      "\n",
      "Test save: ./processed/test_metrics_summary.csv\n",
      "\n",
      " AUROC fold mean: 0.6829, std: 0.1357\n",
      " AUPR   fold mean: 0.7281, std: 0.1332\n"
     ]
    }
   ],
   "source": [
    "# test_xgboost.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, average_precision_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "def evaluate_model_on_test(fold, save_dir):\n",
    "    # 1) 테스트 데이터 로드\n",
    "    test_path = os.path.join(save_dir, f'XGB_test_fold{fold}.pt')\n",
    "    data = torch.load(test_path)\n",
    "    X_test = data['features'].numpy()\n",
    "    y_test = data['labels'].numpy()\n",
    "\n",
    "    # 2) 모델 로드\n",
    "    model_path = os.path.join(save_dir, f'xgboost_fold{fold}.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    # 3) 예측 및 확률\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # 4) 평가 지표 계산\n",
    "    metrics = {\n",
    "        'fold': fold,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba),\n",
    "        'avg_precision': average_precision_score(y_test, y_proba),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def main():\n",
    "    save_dir = './processed'   # 학습 스크립트에서 사용한 경로와 동일하게 설정\n",
    "    n_splits = 20\n",
    "\n",
    "    all_metrics = []\n",
    "    for fold in range(1, n_splits+1):\n",
    "        print(f'Evaluating fold {fold}...')\n",
    "        try:\n",
    "            m = evaluate_model_on_test(fold, save_dir)\n",
    "            all_metrics.append(m)\n",
    "            print(f' Fold {fold} metrics: {m}')\n",
    "        except FileNotFoundError as e:\n",
    "            print(f'  파일을 찾을 수 없습니다: {e}')\n",
    "\n",
    "    # 5) 개별 Fold 지표 DataFrame 생성\n",
    "    df_metrics = pd.DataFrame(all_metrics)\n",
    "\n",
    "    # 6) Fold별 평균(mean) row 추가\n",
    "    mean_row = df_metrics.mean(numeric_only=True).to_dict()\n",
    "    mean_row['fold'] = 'mean'\n",
    "    df_metrics = df_metrics.append(mean_row, ignore_index=True)\n",
    "\n",
    "    # 7) 결과를 CSV로 저장\n",
    "    output_path = os.path.join(save_dir, 'test_metrics_summary.csv')\n",
    "    df_metrics.to_csv(output_path, index=False)\n",
    "    print(f'\\nTest save: {output_path}')\n",
    "\n",
    "    # 8) AUROC와 AUPR의 fold별 평균 및 표준편차 계산\n",
    "    #    (mean_row 에는 평균만 들어있으므로, 원본 all_metrics 로 std 계산)\n",
    "    df_orig = pd.DataFrame(all_metrics)\n",
    "    roc_mean = df_orig['roc_auc'].mean()\n",
    "    roc_std  = df_orig['roc_auc'].std()\n",
    "    aupr_mean = df_orig['avg_precision'].mean()\n",
    "    aupr_std  = df_orig['avg_precision'].std()\n",
    "\n",
    "    print(f\"\\n AUROC fold mean: {roc_mean:.4f}, std: {roc_std:.4f}\")\n",
    "    print(f\" AUPR   fold mean: {aupr_mean:.4f}, std: {aupr_std:.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a30242-3272-442a-a923-8bf38de63272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yunjumulti2",
   "language": "python",
   "name": "yunjumulti2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
