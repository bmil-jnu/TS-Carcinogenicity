{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309da3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from math import sqrt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, MolFromSmiles\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch_geometric import data as DATA\n",
    "from torch_geometric.data import Dataset, Data, DataLoader, InMemoryDataset, Batch\n",
    "from torch_geometric.nn import GATConv, GCNConv, global_max_pool as gmp, global_mean_pool as gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65374052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_features(atom, explicit_H = False, use_chirality=True):\n",
    "    symbol_one_hot = one_of_k_encoding_unk(\n",
    "      atom.GetSymbol(), #37\n",
    "      ['Al', 'Sb', 'Cl', 'Te', 'Si', 'Br', 'Cd', 'S', 'Mn', 'Ba',\n",
    "       'Ga', 'Cr', 'I', 'Mo', 'B', 'Te', 'As', 'Sb', 'N', 'V',\n",
    "       'Sn', 'P', 'Sb', 'Ni', 'Pb', 'Se', 'In', 'Be', 'F','Ti',\n",
    "       'O', 'Hg', 'H', 'C', 'Co', 'Fe', 'Zr'])\n",
    "    \n",
    "    degree_one_hot = one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4 ,5]) #차수\n",
    "    formal_charge_one_hot = one_of_k_encoding_unk(atom.GetFormalCharge(),[-1, 0, 1]) #형식전하\n",
    "    explicit_valence_one_hot = one_of_k_encoding(atom.GetExplicitValence(), [0, 1, 2, 3, 4, 5, 6]) #명시적원자가\n",
    "    implicit_valence_one_hot = one_of_k_encoding(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6])\n",
    "    hybridization_one_hot = one_of_k_encoding_unk(atom.GetHybridization(), [\n",
    "                Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3]) #혼성화\n",
    "    aromatic_one_hot = [atom.GetIsAromatic()]\n",
    "\n",
    "    radical_one_hot = one_of_k_encoding_unk(atom.GetNumRadicalElectrons(), [0, 1, 2])\n",
    "\n",
    "    results = radical_one_hot +symbol_one_hot + degree_one_hot + explicit_valence_one_hot +implicit_valence_one_hot+formal_charge_one_hot + hybridization_one_hot + aromatic_one_hot\n",
    "\n",
    "    if not explicit_H:\n",
    "        total_num_hs_one_hot = one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4 ])\n",
    "        results = results + total_num_hs_one_hot\n",
    "        \n",
    "    if use_chirality:\n",
    "        try:\n",
    "            chirality_one_hot = one_of_k_encoding_unk(\n",
    "                atom.GetProp('_CIPCode'),\n",
    "                ['R', 'S'])\n",
    "            results = results + chirality_one_hot + [atom.HasProp('_ChiralityPossible')]\n",
    "        except:\n",
    "            results = results + [False, False] + [atom.HasProp('_ChiralityPossible')]\n",
    "    \n",
    "    return np.array(results)\n",
    "    \n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\"input {0} not in allowable set{1}:\".format(x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "def smile_to_graph(smile):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "\n",
    "    if mol is None:  # if the molecule is not parsed correctly by RDKit, return None\n",
    "        return None\n",
    "    \n",
    "    c_size = mol.GetNumAtoms()\n",
    "    \n",
    "    features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        feature = atom_features(atom)\n",
    "        features.append(feature / sum(feature))\n",
    "\n",
    "    edges = []\n",
    "    for bond in mol.GetBonds():\n",
    "        edges.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "    g = nx.Graph(edges).to_directed()    \n",
    "    edge_index = []\n",
    "    for e1, e2 in g.edges:\n",
    "        edge_index.append([e1, e2])\n",
    "\n",
    "    if not edge_index:  # check if edge_index is empty\n",
    "        return None\n",
    "\n",
    "    return c_size, features, edge_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2d89a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                                             SMILES  liv  lun  \\\n",
      "0             0                                       C(/C=C/Cl)Cl  1.0  1.0   \n",
      "1             1                                       C(C(CBr)Br)O  1.0  1.0   \n",
      "2             2            C(C(CBr)Br)OP(=O)(OCC(CBr)Br)OCC(CBr)Br  1.0  1.0   \n",
      "3             3                                      C(C(CCl)Cl)Cl  1.0  0.0   \n",
      "4             4                                  C(C(CO)(CBr)CBr)O  1.0  1.0   \n",
      "..          ...                                                ...  ...  ...   \n",
      "338         338        C1(=C(C(=C(C(=C1Cl)Cl)Cl)Cl)Cl)[N+](=O)[O-]  0.0  0.0   \n",
      "339         339                   C1(=C(C(=NC(=C1Cl)Cl)C(=O)O)Cl)N  0.0  0.0   \n",
      "340         340                    C1(=C(C(C(=C1Cl)Cl)(Cl)Cl)Cl)Cl  0.0  0.0   \n",
      "341         341                               C1(=NC(=NC(=N1)N)N)N  0.0  0.0   \n",
      "342         342  C1(=O)C2(C3(C4(C1(C5(C2(C3(C(C45Cl)(Cl)Cl)Cl)C...  0.0  0.0   \n",
      "\n",
      "     sto  mgl  \n",
      "0    1.0  0.0  \n",
      "1    1.0  1.0  \n",
      "2    1.0  0.0  \n",
      "3    1.0  1.0  \n",
      "4    1.0  1.0  \n",
      "..   ...  ...  \n",
      "338  0.0  0.0  \n",
      "339  0.0  0.0  \n",
      "340  0.0  0.0  \n",
      "341  0.0  0.0  \n",
      "342  0.0  0.0  \n",
      "\n",
      "[343 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/data/home/dbswn0814/2025JCM/data/multi task/tissue_merged_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove rows where the 'SMILES' column contains NaN values\n",
    "df = df.dropna(subset=['SMILES'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b42d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atom feature dimension: 75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "# Generate a random atom (e.g. carbon C)\n",
    "atom = Chem.MolFromSmiles(\"CO\").GetAtomWithIdx(0)\n",
    "\n",
    "features = atom_features(atom)\n",
    "\n",
    "print(\"Atom feature dimension:\", len(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c48520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['SMILES'])  \n",
    "list_tissue = ['liv', 'lun', 'sto', 'mgl']\n",
    "smiles_list = df['SMILES'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e948afee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid SMILES: []\n",
      "Length of data: 343\n"
     ]
    }
   ],
   "source": [
    "valid_dataX = []\n",
    "valid_smiles_list = []\n",
    "valid_labels = [[] for _ in range(len(list_tissue))]  \n",
    "invalid_smiles_list = []  \n",
    "\n",
    "for i, smiles in enumerate(smiles_list):\n",
    "    g = smile_to_graph(smiles)\n",
    "    if g is not None:\n",
    "        valid_dataX.append(g)\n",
    "        valid_smiles_list.append(smiles)\n",
    "        for idx, tissue in enumerate(list_tissue):\n",
    "            label = df[tissue].iloc[i]\n",
    "            if pd.isnull(label):\n",
    "                valid_labels[idx].append(-1)  \n",
    "            else:\n",
    "                valid_labels[idx].append(int(label)) \n",
    "    else:\n",
    "        invalid_smiles_list.append(smiles) \n",
    "\n",
    "print(\"Invalid SMILES:\", invalid_smiles_list)\n",
    "\n",
    "val_data = np.array(valid_dataX,dtype=object)\n",
    "val_label = np.array(valid_labels)\n",
    "\n",
    "# Save data\n",
    "np.save('/data/home/dbswn0814/2025JCM/data/multi task/val/multi_refined_data.npy', val_data)\n",
    "np.save('/data/home/dbswn0814/2025JCM/data/multi task/val/multi_refined_labels.npy', val_label)\n",
    "\n",
    "print(\"Length of data:\", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd6ea6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of val_data: 343\n",
      "Tissue liv in cross validation data: 0=166, 1=177, -1=0\n",
      "Tissue lun in cross validation data: 0=159, 1=184, -1=0\n",
      "Tissue sto in cross validation data: 0=157, 1=186, -1=0\n",
      "Tissue mgl in cross validation data: 0=169, 1=174, -1=0\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_label_counts(labels, data_type):\n",
    "    for idx, tissue in enumerate(list_tissue):\n",
    "        labels_for_tissue = labels[idx]  \n",
    "        count_0 = np.sum(labels_for_tissue == 0)\n",
    "        count_1 = np.sum(labels_for_tissue == 1)\n",
    "        count_neg1 = np.sum(labels_for_tissue == -1)\n",
    "        print(f\"Tissue {tissue} in {data_type}: 0={count_0}, 1={count_1}, -1={count_neg1}\")\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Length of val_data:\", len(val_data))\n",
    "\n",
    "\n",
    "print_label_counts(val_label, \"cross validation data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2dfcb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = '/data/home/dbswn0814/2025JCM/data/multi task/val/val_smiles.txt'\n",
    "with open(val_path, 'w', encoding='utf-8') as f:\n",
    "    for item in valid_smiles_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bd1a79",
   "metadata": {},
   "source": [
    "### combination data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52fc1158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File liv_lun_data.csv not found. Skipping...\n",
      "File liv_sto_data.csv not found. Skipping...\n",
      "File liv_mgl_data.csv not found. Skipping...\n",
      "File lun_sto_data.csv not found. Skipping...\n",
      "File lun_mgl_data.csv not found. Skipping...\n",
      "File sto_mgl_data.csv not found. Skipping...\n",
      "Processed liv_lun_sto_data.csv:\n",
      "  Length of data: 10\n",
      "  Invalid SMILES: []\n",
      "Tissue liv in liv_lun_sto: 0=5, 1=5, -1=0\n",
      "Tissue lun in liv_lun_sto: 0=8, 1=2, -1=0\n",
      "Tissue sto in liv_lun_sto: 0=5, 1=5, -1=0\n",
      "------------------------------------------------------------------------\n",
      "Processed liv_lun_mgl_data.csv:\n",
      "  Length of data: 12\n",
      "  Invalid SMILES: []\n",
      "Tissue liv in liv_lun_mgl: 0=7, 1=5, -1=0\n",
      "Tissue lun in liv_lun_mgl: 0=12, 1=0, -1=0\n",
      "Tissue mgl in liv_lun_mgl: 0=7, 1=5, -1=0\n",
      "------------------------------------------------------------------------\n",
      "Processed liv_sto_mgl_data.csv:\n",
      "  Length of data: 5\n",
      "  Invalid SMILES: []\n",
      "Tissue liv in liv_sto_mgl: 0=3, 1=2, -1=0\n",
      "Tissue sto in liv_sto_mgl: 0=3, 1=2, -1=0\n",
      "Tissue mgl in liv_sto_mgl: 0=3, 1=2, -1=0\n",
      "------------------------------------------------------------------------\n",
      "Processed lun_sto_mgl_data.csv:\n",
      "  Length of data: 6\n",
      "  Invalid SMILES: []\n",
      "Tissue lun in lun_sto_mgl: 0=2, 1=4, -1=0\n",
      "Tissue sto in lun_sto_mgl: 0=0, 1=6, -1=0\n",
      "Tissue mgl in lun_sto_mgl: 0=0, 1=6, -1=0\n",
      "------------------------------------------------------------------------\n",
      "File liv_lun_sto_mgl_data.csv not found. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import os\n",
    "\n",
    "# List of tissues\n",
    "tissues = ['liv', 'lun', 'sto', 'mgl']\n",
    "\n",
    "# Generate all possible non-redundant combinations of tissue names\n",
    "all_combinations = []\n",
    "for i in range(2, len(tissues) + 1): \n",
    "    all_combinations.extend(combinations(tissues, i))\n",
    "\n",
    "# Base directory for loading and saving data\n",
    "base_dir = '/data/home/dbswn0814/2025JCM/data/multi task'\n",
    "\n",
    "for list_tissue in all_combinations:\n",
    "    tissue_comb_name = '_'.join(list_tissue)\n",
    "    file_name = f\"{tissue_comb_name}_data.csv\"\n",
    "    file_path = os.path.join(base_dir, file_name)\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_name} not found. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Remove rows where the 'SMILES' column contains NaN values\n",
    "    df = df.dropna(subset=['SMILES'])\n",
    "\n",
    "    smiles_list = df['SMILES'].tolist()\n",
    "\n",
    "    valid_dataX = []\n",
    "    valid_smiles_list = []\n",
    "    valid_labels = [[] for _ in range(len(list_tissue))]\n",
    "    invalid_smiles_list = []\n",
    "\n",
    "    # Filter valid SMILES and labels\n",
    "    for i, smiles in enumerate(smiles_list):\n",
    "        g = smile_to_graph(smiles)  \n",
    "        if g is not None:\n",
    "            valid_dataX.append(g)\n",
    "            valid_smiles_list.append(smiles)\n",
    "            for idx, tissue in enumerate(list_tissue):\n",
    "                column_name = f\"result_{tissue}\"  \n",
    "                if column_name not in df.columns:\n",
    "                    raise KeyError(f\"Column {column_name} not found in {file_name}\")\n",
    "                label = df[column_name].iloc[i]\n",
    "                if pd.isnull(label):\n",
    "                    valid_labels[idx].append(-1)\n",
    "                else:\n",
    "                    valid_labels[idx].append(int(label))\n",
    "        else:\n",
    "            invalid_smiles_list.append(smiles)\n",
    "\n",
    "    # Save the valid data and labels\n",
    "    val_data = np.array(valid_dataX, dtype=object)\n",
    "    val_label = np.array(valid_labels)\n",
    "\n",
    "    np.save(os.path.join(base_dir, f\"val/{tissue_comb_name}_data.npy\"), val_data)\n",
    "    np.save(os.path.join(base_dir, f\"val/{tissue_comb_name}_labels.npy\"), val_label)\n",
    "\n",
    "    # Save the valid SMILES to a text file\n",
    "    val_path = os.path.join(base_dir, f\"val/{tissue_comb_name}_smiles.txt\")\n",
    "    with open(val_path, 'w', encoding='utf-8') as f:\n",
    "        for item in valid_smiles_list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Processed {file_name}:\")\n",
    "    print(f\"  Length of data: {len(val_data)}\")\n",
    "    print(f\"  Invalid SMILES: {invalid_smiles_list}\")\n",
    "\n",
    "    # Print label counts\n",
    "    def print_label_counts(labels, data_type):\n",
    "        for idx, tissue in enumerate(list_tissue):\n",
    "            labels_for_tissue = labels[idx]\n",
    "            count_0 = np.sum(labels_for_tissue == 0)\n",
    "            count_1 = np.sum(labels_for_tissue == 1)\n",
    "            count_neg1 = np.sum(labels_for_tissue == -1)\n",
    "            print(f\"Tissue {tissue} in {data_type}: 0={count_0}, 1={count_1}, -1={count_neg1}\")\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "\n",
    "    print_label_counts(val_label, tissue_comb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db3020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yunjumulti2",
   "language": "python",
   "name": "yunjumulti2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
