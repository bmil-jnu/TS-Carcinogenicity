{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309da3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from math import sqrt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, MolFromSmiles\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch_geometric import data as DATA\n",
    "from torch_geometric.data import Dataset, Data, DataLoader, InMemoryDataset, Batch\n",
    "from torch_geometric.nn import GATConv, GCNConv, global_max_pool as gmp, global_mean_pool as gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65374052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#원본\n",
    "def atom_features(atom, explicit_H = False, use_chirality=True):\n",
    "    symbol_one_hot = one_of_k_encoding_unk(\n",
    "      atom.GetSymbol(), #37\n",
    "      ['Al', 'Sb', 'Cl', 'Te', 'Si', 'Br', 'Cd', 'S', 'Mn', 'Ba',\n",
    "       'Ga', 'Cr', 'I', 'Mo', 'B', 'Te', 'As', 'Sb', 'N', 'V',\n",
    "       'Sn', 'P', 'Sb', 'Ni', 'Pb', 'Se', 'In', 'Be', 'F','Ti',\n",
    "       'O', 'Hg', 'H', 'C', 'Co', 'Fe', 'Zr'])\n",
    "    \n",
    "    degree_one_hot = one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4 ,5]) #차수\n",
    "    formal_charge_one_hot = one_of_k_encoding_unk(atom.GetFormalCharge(),[-1, 0, 1]) #형식전하\n",
    "    explicit_valence_one_hot = one_of_k_encoding(atom.GetExplicitValence(), [0, 1, 2, 3, 4, 5, 6]) #명시적원자가\n",
    "    implicit_valence_one_hot = one_of_k_encoding(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6])\n",
    "    hybridization_one_hot = one_of_k_encoding_unk(atom.GetHybridization(), [\n",
    "                Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3]) #혼성화\n",
    "    aromatic_one_hot = [atom.GetIsAromatic()]\n",
    "\n",
    "    radical_one_hot = one_of_k_encoding_unk(atom.GetNumRadicalElectrons(), [0, 1, 2])\n",
    "\n",
    "    results = radical_one_hot +symbol_one_hot + degree_one_hot + explicit_valence_one_hot +implicit_valence_one_hot+formal_charge_one_hot + hybridization_one_hot + aromatic_one_hot\n",
    "#    results = radical_one_hot +symbol_one_hot + degree_one_hot + explicit_valence_one_hot +formal_charge_one_hot + hybridization_one_hot + aromatic_one_hot\n",
    "\n",
    "    #false인 경우 명시적 수소수가 아니라 총 수소수를 반환\n",
    "    if not explicit_H:\n",
    "        total_num_hs_one_hot = one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4 ])\n",
    "        results = results + total_num_hs_one_hot\n",
    "        \n",
    "    if use_chirality:\n",
    "        try:\n",
    "#             print(atom.GetProp('_CIPCode'))  # 카이랄성 정보 출력\n",
    "            chirality_one_hot = one_of_k_encoding_unk(\n",
    "                atom.GetProp('_CIPCode'),\n",
    "                ['R', 'S'])\n",
    "            results = results + chirality_one_hot + [atom.HasProp('_ChiralityPossible')]\n",
    "        except:\n",
    "#             print(\"Chirality information not available.\")  # 카이랄성 정보가 없는 경우\n",
    "            results = results + [False, False] + [atom.HasProp('_ChiralityPossible')]\n",
    "    \n",
    "    return np.array(results)\n",
    "    \n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\"input {0} not in allowable set{1}:\".format(x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "def smile_to_graph(smile):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "\n",
    "    if mol is None:  # if the molecule is not parsed correctly by RDKit, return None\n",
    "        return None\n",
    "    \n",
    "    c_size = mol.GetNumAtoms()\n",
    "    \n",
    "    features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        feature = atom_features(atom)\n",
    "        features.append(feature / sum(feature))\n",
    "#     print(\"Length of atom feature:\", len(feature))  # 각 원자의 feature vector의 차원을 출력\n",
    "\n",
    "    edges = []\n",
    "    for bond in mol.GetBonds():\n",
    "        edges.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "    g = nx.Graph(edges).to_directed()    \n",
    "    edge_index = []\n",
    "    for e1, e2 in g.edges:\n",
    "        edge_index.append([e1, e2])\n",
    "\n",
    "    if not edge_index:  # check if edge_index is empty\n",
    "        return None\n",
    "\n",
    "    return c_size, features, edge_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e504f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def atom_features(atom, explicit_H = False, use_chirality=True):\n",
    "#     symbol_one_hot = one_of_k_encoding_unk(\n",
    "#       atom.GetSymbol(), #37\n",
    "#       [ 'Sb', 'Cl', 'Te', 'Si', 'Br', 'Cd', 'S',\n",
    "#        'Ga', 'I', 'Mo', 'Te', 'As', 'N', 'V',\n",
    "#        'Sn', 'P', 'Sb', 'Ni',  'F','Ti',\n",
    "#        'O', 'Hg', 'C', 'Co'])\n",
    "    \n",
    "#     degree_one_hot = one_of_k_encoding(atom.GetDegree(), [1, 2, 3, 4 ]) #차수\n",
    "#     formal_charge_one_hot = one_of_k_encoding_unk(atom.GetFormalCharge(),[-1, 0, 1]) #형식전하\n",
    "#     explicit_valence_one_hot = one_of_k_encoding(atom.GetExplicitValence(), [1, 2, 3, 4, 5, 6]) #명시적원자가\n",
    "#     implicit_valence_one_hot = one_of_k_encoding(atom.GetImplicitValence(), [0, 1, 2, 3])\n",
    "#     hybridization_one_hot = one_of_k_encoding_unk(atom.GetHybridization(), [\n",
    "#                 Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "#                 Chem.rdchem.HybridizationType.SP3]) #혼성화\n",
    "#     aromatic_one_hot = [atom.GetIsAromatic()]\n",
    "\n",
    "#     radical_one_hot = one_of_k_encoding_unk(atom.GetNumRadicalElectrons(), [0, 1])\n",
    "\n",
    "#     results = radical_one_hot +symbol_one_hot + degree_one_hot + explicit_valence_one_hot +implicit_valence_one_hot+formal_charge_one_hot + hybridization_one_hot + aromatic_one_hot\n",
    "# #    results = radical_one_hot +symbol_one_hot + degree_one_hot + explicit_valence_one_hot +formal_charge_one_hot + hybridization_one_hot + aromatic_one_hot\n",
    "\n",
    "#     #false인 경우 명시적 수소수가 아니라 총 수소수를 반환\n",
    "#     if not explicit_H:\n",
    "#         total_num_hs_one_hot = one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3])\n",
    "#         results = results + total_num_hs_one_hot\n",
    "        \n",
    "#     if use_chirality:\n",
    "#         try:\n",
    "# #             print(atom.GetProp('_CIPCode'))  # 카이랄성 정보 출력\n",
    "#             chirality_one_hot = one_of_k_encoding_unk(\n",
    "#                 atom.GetProp('_CIPCode'),\n",
    "#                 ['R', 'S'])\n",
    "#             results = results + chirality_one_hot + [atom.HasProp('_ChiralityPossible')]\n",
    "#         except:\n",
    "# #             print(\"Chirality information not available.\")  # 카이랄성 정보가 없는 경우\n",
    "#             results = results + [False, False] + [atom.HasProp('_ChiralityPossible')]\n",
    "    \n",
    "#     return np.array(results)\n",
    "    \n",
    "\n",
    "# def one_of_k_encoding(x, allowable_set):\n",
    "#     if x not in allowable_set:\n",
    "#         raise Exception(\"input {0} not in allowable set{1}:\".format(x, allowable_set))\n",
    "#     return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "# def one_of_k_encoding_unk(x, allowable_set):\n",
    "#     \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "#     if x not in allowable_set:\n",
    "#         x = allowable_set[-1]\n",
    "#     return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "# def smile_to_graph(smile):\n",
    "#     mol = Chem.MolFromSmiles(smile)\n",
    "\n",
    "#     if mol is None:  # if the molecule is not parsed correctly by RDKit, return None\n",
    "#         return None\n",
    "    \n",
    "#     c_size = mol.GetNumAtoms()\n",
    "    \n",
    "#     features = []\n",
    "#     for atom in mol.GetAtoms():\n",
    "#         feature = atom_features(atom)\n",
    "#         features.append(feature / sum(feature))\n",
    "# #     print(\"Length of atom feature:\", len(feature))  # 각 원자의 feature vector의 차원을 출력\n",
    "\n",
    "#     edges = []\n",
    "#     for bond in mol.GetBonds():\n",
    "#         edges.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "#     g = nx.Graph(edges).to_directed()    \n",
    "#     edge_index = []\n",
    "#     for e1, e2 in g.edges:\n",
    "#         edge_index.append([e1, e2])\n",
    "\n",
    "#     if not edge_index:  # check if edge_index is empty\n",
    "#         return None\n",
    "\n",
    "#     return c_size, features, edge_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2d89a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                                             SMILES  liv  lun  \\\n",
      "0             0                                       C(/C=C/Cl)Cl  1.0  1.0   \n",
      "1             1                                       C(C(CBr)Br)O  1.0  1.0   \n",
      "2             2            C(C(CBr)Br)OP(=O)(OCC(CBr)Br)OCC(CBr)Br  1.0  1.0   \n",
      "3             3                                      C(C(CCl)Cl)Cl  1.0  0.0   \n",
      "4             4                                  C(C(CO)(CBr)CBr)O  1.0  1.0   \n",
      "..          ...                                                ...  ...  ...   \n",
      "338         338        C1(=C(C(=C(C(=C1Cl)Cl)Cl)Cl)Cl)[N+](=O)[O-]  0.0  0.0   \n",
      "339         339                   C1(=C(C(=NC(=C1Cl)Cl)C(=O)O)Cl)N  0.0  0.0   \n",
      "340         340                    C1(=C(C(C(=C1Cl)Cl)(Cl)Cl)Cl)Cl  0.0  0.0   \n",
      "341         341                               C1(=NC(=NC(=N1)N)N)N  0.0  0.0   \n",
      "342         342  C1(=O)C2(C3(C4(C1(C5(C2(C3(C(C45Cl)(Cl)Cl)Cl)C...  0.0  0.0   \n",
      "\n",
      "     sto  mgl  \n",
      "0    1.0  0.0  \n",
      "1    1.0  1.0  \n",
      "2    1.0  0.0  \n",
      "3    1.0  1.0  \n",
      "4    1.0  1.0  \n",
      "..   ...  ...  \n",
      "338  0.0  0.0  \n",
      "339  0.0  0.0  \n",
      "340  0.0  0.0  \n",
      "341  0.0  0.0  \n",
      "342  0.0  0.0  \n",
      "\n",
      "[343 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/data/home/dbswn0814/2025JCM/data/multi task/tissue_merged_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove rows where the 'SMILES' column contains NaN values\n",
    "df = df.dropna(subset=['SMILES'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7bc617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터에서 사용할 원소 기호 리스트\n",
    "# allowed_symbols = set(['Al', 'Sb', 'Cl', 'Te', 'Si', 'Br', 'Cd', 'S', 'Mn', 'Ba',\n",
    "#        'Ga', 'Cr', 'I', 'Mo', 'B', 'Te', 'As', 'Sb', 'N', 'V',\n",
    "#        'Sn', 'P', 'Sb', 'Ni', 'Pb', 'Se', 'In', 'Be', 'F','Ti',\n",
    "#        'O', 'Hg', 'H', 'C', 'Co', 'Fe', 'Zr'])\n",
    "\n",
    "# # 데이터셋에서 SMILES 가져오기\n",
    "# smiles_list = df['SMILES'].tolist()\n",
    "\n",
    "# # SMILES 데이터에서 실제로 등장하는 원소 찾기\n",
    "# found_symbols = set()\n",
    "\n",
    "# for smiles in smiles_list:\n",
    "#     mol = Chem.MolFromSmiles(smiles)  # SMILES를 RDKit 분자로 변환\n",
    "#     if mol:\n",
    "#         for atom in mol.GetAtoms():\n",
    "#             found_symbols.add(atom.GetSymbol())  # 원자 기호 추출\n",
    "\n",
    "# # ✅ 실제 데이터에 등장하지 않는 원소 찾기\n",
    "# unused_symbols = allowed_symbols - found_symbols  # `allowed_symbols` 중 SMILES에 없는 원소\n",
    "\n",
    "# # 결과 출력\n",
    "# if not unused_symbols:\n",
    "#     print(\"`allowed_symbols`에 불필요한 원소가 없음.\")\n",
    "# else:\n",
    "#     print(\"`allowed_symbols`에 포함되어 있지만 데이터에 없는 원소 발견!\")\n",
    "#     print(\" 데이터에서 사용되지 않은 원소:\", unused_symbols)\n",
    "\n",
    "    \n",
    "# # 허용된 값 리스트들\n",
    "# allowed_degrees = set([0, 1, 2, 3, 4 ,5])  # 원자 차수\n",
    "# allowed_formal_charges = set([-1, 0, 1])  # 형식 전하\n",
    "# allowed_explicit_valences = set( [0, 1, 2, 3, 4, 5, 6])  # 명시적 원자가\n",
    "# allowed_implicit_valences = set( [0, 1, 2, 3, 4, 5, 6])  # 암묵적 원자가\n",
    "# allowed_hybridizations = set([\n",
    "#     Chem.rdchem.HybridizationType.SP, \n",
    "#     Chem.rdchem.HybridizationType.SP2, \n",
    "#     Chem.rdchem.HybridizationType.SP3\n",
    "# ])  # 혼성화\n",
    "# allowed_radical_electrons = set([0, 1, 2])  # 라디칼 전자 수\n",
    "# allowed_total_hs = set([0, 1, 2, 3, 4 ])  # 총 수소 수\n",
    "# allowed_chirality = set(['R', 'S'])  # 카이랄성\n",
    "\n",
    "# # 실제 데이터에서 등장하는 값 저장\n",
    "# found_degrees = set()\n",
    "# found_formal_charges = set()\n",
    "# found_explicit_valences = set()\n",
    "# found_implicit_valences = set()\n",
    "# found_hybridizations = set()\n",
    "# found_radical_electrons = set()\n",
    "# found_total_hs = set()\n",
    "# found_chirality = set()\n",
    "\n",
    "# # 데이터셋에서 SMILES 가져오기\n",
    "# smiles_list = df['SMILES'].tolist()\n",
    "\n",
    "# for smiles in smiles_list:\n",
    "#     mol = Chem.MolFromSmiles(smiles)\n",
    "#     if mol:\n",
    "#         for atom in mol.GetAtoms():\n",
    "#             # 등장한 값 저장\n",
    "#             found_degrees.add(atom.GetDegree())\n",
    "#             found_formal_charges.add(atom.GetFormalCharge())\n",
    "#             found_explicit_valences.add(atom.GetExplicitValence())\n",
    "#             found_implicit_valences.add(atom.GetImplicitValence())\n",
    "#             found_hybridizations.add(atom.GetHybridization())\n",
    "#             found_radical_electrons.add(atom.GetNumRadicalElectrons())\n",
    "#             found_total_hs.add(atom.GetTotalNumHs())\n",
    "#             if atom.HasProp('_CIPCode'):\n",
    "#                 found_chirality.add(atom.GetProp('_CIPCode'))\n",
    "\n",
    "# # 허용된 값과 실제 등장한 값 비교\n",
    "# unused_degrees = allowed_degrees - found_degrees\n",
    "# unused_formal_charges = allowed_formal_charges - found_formal_charges\n",
    "# unused_explicit_valences = allowed_explicit_valences - found_explicit_valences\n",
    "# unused_implicit_valences = allowed_implicit_valences - found_implicit_valences\n",
    "# unused_hybridizations = allowed_hybridizations - found_hybridizations\n",
    "# unused_radical_electrons = allowed_radical_electrons - found_radical_electrons\n",
    "# unused_total_hs = allowed_total_hs - found_total_hs\n",
    "# unused_chirality = allowed_chirality - found_chirality\n",
    "\n",
    "# # 결과 출력\n",
    "# print(\"데이터에 등장하지 않은 값들:\")\n",
    "# if unused_degrees:\n",
    "#     print(f\"  사용되지 않은 원자 차수 (Degree): {unused_degrees}\")\n",
    "# if unused_formal_charges:\n",
    "#     print(f\"  사용되지 않은 형식 전하 (Formal Charge): {unused_formal_charges}\")\n",
    "# if unused_explicit_valences:\n",
    "#     print(f\"  사용되지 않은 명시적 원자가 (Explicit Valence): {unused_explicit_valences}\")\n",
    "# if unused_implicit_valences:\n",
    "#     print(f\"  사용되지 않은 암묵적 원자가 (Implicit Valence): {unused_implicit_valences}\")\n",
    "# if unused_hybridizations:\n",
    "#     print(f\"  사용되지 않은 혼성화 (Hybridization): {unused_hybridizations}\")\n",
    "# if unused_radical_electrons:\n",
    "#     print(f\"  사용되지 않은 라디칼 전자 수 (Radical Electrons): {unused_radical_electrons}\")\n",
    "# if unused_total_hs:\n",
    "#     print(f\"  사용되지 않은 총 수소 수 (Total Num Hs): {unused_total_hs}\")\n",
    "# if unused_chirality:\n",
    "#     print(f\"  사용되지 않은 카이랄성 값 (Chirality): {unused_chirality}\")\n",
    "\n",
    "# if not (unused_degrees or unused_formal_charges or unused_explicit_valences or unused_implicit_valences or unused_hybridizations or unused_radical_electrons or unused_total_hs or unused_chirality):\n",
    "#     print(\" 모든 허용된 값들이 실제 데이터에서 사용됨.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b42d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atom feature dimension: 75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "# 임의의 원자 (예: 탄소 C) 생성\n",
    "atom = Chem.MolFromSmiles(\"CO\").GetAtomWithIdx(0)\n",
    "\n",
    "# 원자 특징 벡터 생성\n",
    "features = atom_features(atom)\n",
    "\n",
    "# 차원 출력\n",
    "print(\"Atom feature dimension:\", len(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c48520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['SMILES'])  # SMILES 열에 NaN이 있는 행을 제거\n",
    "list_tissue = ['liv', 'lun', 'sto', 'mgl']\n",
    "smiles_list = df['SMILES'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e948afee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid SMILES: []\n",
      "Length of data: 343\n"
     ]
    }
   ],
   "source": [
    "valid_dataX = []\n",
    "valid_smiles_list = []\n",
    "valid_labels = [[] for _ in range(len(list_tissue))]  # 각 태스크별 레이블을 저장할 리스트\n",
    "invalid_smiles_list = []  # 유효하지 않은 SMILES를 저장할 리스트\n",
    "\n",
    "# 유효한 SMILES와 레이블을 필터링\n",
    "for i, smiles in enumerate(smiles_list):\n",
    "    g = smile_to_graph(smiles)\n",
    "    if g is not None:\n",
    "        valid_dataX.append(g)\n",
    "        valid_smiles_list.append(smiles)\n",
    "        for idx, tissue in enumerate(list_tissue):\n",
    "            label = df[tissue].iloc[i]\n",
    "            if pd.isnull(label):\n",
    "                valid_labels[idx].append(-1)  # 레이블이 NaN인 경우 -1로 처리\n",
    "            else:\n",
    "                valid_labels[idx].append(int(label))  # 레이블이 유효한 경우 해당 레이블로 처리\n",
    "    else:\n",
    "        invalid_smiles_list.append(smiles)  # 유효하지 않은 SMILES를 저장\n",
    "\n",
    "# 유효하지 않은 SMILES들을 출력\n",
    "print(\"Invalid SMILES:\", invalid_smiles_list)\n",
    "\n",
    "val_data = np.array(valid_dataX,dtype=object)\n",
    "val_label = np.array(valid_labels)\n",
    "\n",
    "\n",
    "# Save data: train, validation, and test\n",
    "np.save('/data/home/dbswn0814/2025JCM/data/multi task/val/multi_refined_data.npy', val_data)\n",
    "np.save('/data/home/dbswn0814/2025JCM/data/multi task/val/multi_refined_labels.npy', val_label)\n",
    "\n",
    "# Since our data is already in the desired format, no need for further transformations.\n",
    "print(\"Length of data:\", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd6ea6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of val_data: 343\n",
      "Tissue liv in cross validation data: 0=166, 1=177, -1=0\n",
      "Tissue lun in cross validation data: 0=159, 1=184, -1=0\n",
      "Tissue sto in cross validation data: 0=157, 1=186, -1=0\n",
      "Tissue mgl in cross validation data: 0=169, 1=174, -1=0\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 각 list_tissue별 0과 1과 -1의 개수 출력\n",
    "def print_label_counts(labels, data_type):\n",
    "    for idx, tissue in enumerate(list_tissue):\n",
    "        labels_for_tissue = labels[idx]  # (tasks, samples) 형식에서 각 태스크의 레이블\n",
    "        count_0 = np.sum(labels_for_tissue == 0)\n",
    "        count_1 = np.sum(labels_for_tissue == 1)\n",
    "        count_neg1 = np.sum(labels_for_tissue == -1)\n",
    "        print(f\"Tissue {tissue} in {data_type}: 0={count_0}, 1={count_1}, -1={count_neg1}\")\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Length of val_data:\", len(val_data))\n",
    "\n",
    "\n",
    "print_label_counts(val_label, \"cross validation data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2dfcb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = '/data/home/dbswn0814/2025JCM/data/multi task/val/val_smiles.txt'\n",
    "with open(val_path, 'w', encoding='utf-8') as f:\n",
    "    for item in valid_smiles_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bd1a79",
   "metadata": {},
   "source": [
    "### combination data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52fc1158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File liv_lun_data.csv not found. Skipping...\n",
      "File liv_sto_data.csv not found. Skipping...\n",
      "File liv_mgl_data.csv not found. Skipping...\n",
      "File lun_sto_data.csv not found. Skipping...\n",
      "File lun_mgl_data.csv not found. Skipping...\n",
      "File sto_mgl_data.csv not found. Skipping...\n",
      "Processed liv_lun_sto_data.csv:\n",
      "  Length of data: 10\n",
      "  Invalid SMILES: []\n",
      "Tissue liv in liv_lun_sto: 0=5, 1=5, -1=0\n",
      "Tissue lun in liv_lun_sto: 0=8, 1=2, -1=0\n",
      "Tissue sto in liv_lun_sto: 0=5, 1=5, -1=0\n",
      "------------------------------------------------------------------------\n",
      "Processed liv_lun_mgl_data.csv:\n",
      "  Length of data: 12\n",
      "  Invalid SMILES: []\n",
      "Tissue liv in liv_lun_mgl: 0=7, 1=5, -1=0\n",
      "Tissue lun in liv_lun_mgl: 0=12, 1=0, -1=0\n",
      "Tissue mgl in liv_lun_mgl: 0=7, 1=5, -1=0\n",
      "------------------------------------------------------------------------\n",
      "Processed liv_sto_mgl_data.csv:\n",
      "  Length of data: 5\n",
      "  Invalid SMILES: []\n",
      "Tissue liv in liv_sto_mgl: 0=3, 1=2, -1=0\n",
      "Tissue sto in liv_sto_mgl: 0=3, 1=2, -1=0\n",
      "Tissue mgl in liv_sto_mgl: 0=3, 1=2, -1=0\n",
      "------------------------------------------------------------------------\n",
      "Processed lun_sto_mgl_data.csv:\n",
      "  Length of data: 6\n",
      "  Invalid SMILES: []\n",
      "Tissue lun in lun_sto_mgl: 0=2, 1=4, -1=0\n",
      "Tissue sto in lun_sto_mgl: 0=0, 1=6, -1=0\n",
      "Tissue mgl in lun_sto_mgl: 0=0, 1=6, -1=0\n",
      "------------------------------------------------------------------------\n",
      "File liv_lun_sto_mgl_data.csv not found. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import os\n",
    "\n",
    "# List of tissues\n",
    "tissues = ['liv', 'lun', 'sto', 'mgl']\n",
    "\n",
    "# Generate all possible non-redundant combinations of tissue names\n",
    "all_combinations = []\n",
    "for i in range(2, len(tissues) + 1):  # 최소 2개 이상의 조합을 고려\n",
    "    all_combinations.extend(combinations(tissues, i))\n",
    "\n",
    "# Base directory for loading and saving data\n",
    "base_dir = '/data/home/dbswn0814/2025JCM/data/multi task'\n",
    "\n",
    "for list_tissue in all_combinations:\n",
    "    # Generate the file name from the combination (e.g., 'liv_lun_data.csv')\n",
    "    tissue_comb_name = '_'.join(list_tissue)\n",
    "    file_name = f\"{tissue_comb_name}_data.csv\"\n",
    "    file_path = os.path.join(base_dir, file_name)\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_name} not found. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Remove rows where the 'SMILES' column contains NaN values\n",
    "    df = df.dropna(subset=['SMILES'])\n",
    "\n",
    "    smiles_list = df['SMILES'].tolist()\n",
    "\n",
    "    valid_dataX = []\n",
    "    valid_smiles_list = []\n",
    "    valid_labels = [[] for _ in range(len(list_tissue))]\n",
    "    invalid_smiles_list = []\n",
    "\n",
    "    # Filter valid SMILES and labels\n",
    "    for i, smiles in enumerate(smiles_list):\n",
    "        g = smile_to_graph(smiles)  # Replace this with your actual graph conversion function\n",
    "        if g is not None:\n",
    "            valid_dataX.append(g)\n",
    "            valid_smiles_list.append(smiles)\n",
    "            for idx, tissue in enumerate(list_tissue):\n",
    "                column_name = f\"result_{tissue}\"  # Adjust column name to match format\n",
    "                if column_name not in df.columns:\n",
    "                    raise KeyError(f\"Column {column_name} not found in {file_name}\")\n",
    "                label = df[column_name].iloc[i]\n",
    "                if pd.isnull(label):\n",
    "                    valid_labels[idx].append(-1)\n",
    "                else:\n",
    "                    valid_labels[idx].append(int(label))\n",
    "        else:\n",
    "            invalid_smiles_list.append(smiles)\n",
    "\n",
    "    # Save the valid data and labels\n",
    "    val_data = np.array(valid_dataX, dtype=object)\n",
    "    val_label = np.array(valid_labels)\n",
    "\n",
    "    np.save(os.path.join(base_dir, f\"val/{tissue_comb_name}_data.npy\"), val_data)\n",
    "    np.save(os.path.join(base_dir, f\"val/{tissue_comb_name}_labels.npy\"), val_label)\n",
    "\n",
    "    # Save the valid SMILES to a text file\n",
    "    val_path = os.path.join(base_dir, f\"val/{tissue_comb_name}_smiles.txt\")\n",
    "    with open(val_path, 'w', encoding='utf-8') as f:\n",
    "        for item in valid_smiles_list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Processed {file_name}:\")\n",
    "    print(f\"  Length of data: {len(val_data)}\")\n",
    "    print(f\"  Invalid SMILES: {invalid_smiles_list}\")\n",
    "\n",
    "    # Print label counts\n",
    "    def print_label_counts(labels, data_type):\n",
    "        for idx, tissue in enumerate(list_tissue):\n",
    "            labels_for_tissue = labels[idx]\n",
    "            count_0 = np.sum(labels_for_tissue == 0)\n",
    "            count_1 = np.sum(labels_for_tissue == 1)\n",
    "            count_neg1 = np.sum(labels_for_tissue == -1)\n",
    "            print(f\"Tissue {tissue} in {data_type}: 0={count_0}, 1={count_1}, -1={count_neg1}\")\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "\n",
    "    print_label_counts(val_label, tissue_comb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db3020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yunjumulti2",
   "language": "python",
   "name": "yunjumulti2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
