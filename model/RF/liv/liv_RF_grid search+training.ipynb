{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174793d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 08:33:03.586156: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-26 08:33:04.382915: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-06-26 08:33:04.382979: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-06-26 08:33:04.382984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from scipy import interp\n",
    "from tensorflow.keras.layers import Embedding, Dense \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa561ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e23cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 50}, OOB score: 0.6583\n",
      "Params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100}, OOB score: 0.6667\n",
      "Params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 150}, OOB score: 0.6667\n",
      "Params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 50}, OOB score: 0.6333\n",
      "Params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}, OOB score: 0.6333\n",
      "Params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 150}, OOB score: 0.6500\n",
      "Params: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 50}, OOB score: 0.6458\n",
      "Params: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100}, OOB score: 0.6500\n",
      "Params: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 150}, OOB score: 0.6542\n",
      "Params: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 50}, OOB score: 0.6750\n",
      "Params: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}, OOB score: 0.6708\n",
      "Params: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 150}, OOB score: 0.6542\n",
      "Params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 50}, OOB score: 0.6333\n",
      "Params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100}, OOB score: 0.6417\n",
      "Params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 150}, OOB score: 0.6333\n",
      "Params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 50}, OOB score: 0.6417\n",
      "Params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}, OOB score: 0.6250\n",
      "Params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 150}, OOB score: 0.6333\n",
      "Params: {'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 50}, OOB score: 0.6333\n",
      "Params: {'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100}, OOB score: 0.6417\n",
      "Params: {'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 150}, OOB score: 0.6667\n",
      "Params: {'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 50}, OOB score: 0.6417\n",
      "Params: {'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}, OOB score: 0.6667\n",
      "Params: {'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 150}, OOB score: 0.6625\n",
      "Params: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 50}, OOB score: 0.6458\n",
      "Params: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100}, OOB score: 0.6583\n",
      "Params: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 150}, OOB score: 0.6542\n",
      "Params: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 50}, OOB score: 0.6500\n",
      "Params: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}, OOB score: 0.6500\n",
      "Params: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 150}, OOB score: 0.6542\n",
      "Params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 50}, OOB score: 0.6667\n",
      "Params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100}, OOB score: 0.6625\n",
      "Params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 150}, OOB score: 0.6708\n",
      "Params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 50}, OOB score: 0.6625\n",
      "Params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 100}, OOB score: 0.6375\n",
      "Params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 150}, OOB score: 0.6458\n",
      "Best params: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 50}, Best OOB score: 0.6750\n",
      "OOB-based grid search completed. Test set saved at RF_test_holdout.pt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, QED, DataStructs\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# 1) Load and preprocess data\n",
    "df = pd.read_csv('/data/home/dbswn0814/2025JCM/data/single task/liv_data.csv')\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    df_copy = df.copy().reset_index(drop=True)\n",
    "    mols, invalid_idxs = [], []\n",
    "    for i, smi in enumerate(df_copy['SMILES']):\n",
    "        mol = Chem.MolFromSmiles(str(smi))\n",
    "        if mol:\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mols.append(mol)\n",
    "            except:\n",
    "                invalid_idxs.append(i)\n",
    "                print(f\"Index {i} has invalid SMILES and will be dropped.\")\n",
    "        else:\n",
    "            invalid_idxs.append(i)\n",
    "            print(f\"Index {i} SMILES is None and will be dropped.\")\n",
    "    if invalid_idxs:\n",
    "        df_copy = df_copy.drop(invalid_idxs, axis=0).reset_index(drop=True)\n",
    "    return df_copy, mols\n",
    "\n",
    "# Run preprocessing\n",
    "df_clean, mols = preprocess_dataframe(df)\n",
    "\n",
    "# Generate Morgan fingerprints\n",
    "fps = [AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024) for mol in mols]\n",
    "fingerprints = []\n",
    "for fp in fps:\n",
    "    arr = np.zeros((1024,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    fingerprints.append(arr)\n",
    "x_fp = np.array(fingerprints, dtype=np.float32)\n",
    "\n",
    "# Compute QED properties and scale\n",
    "eq_props = [QED.properties(mol) for mol in mols]\n",
    "qe_df = pd.DataFrame(eq_props)\n",
    "scaler = StandardScaler()\n",
    "qe_scaled = scaler.fit_transform(qe_df)\n",
    "qe_scaled_df = pd.DataFrame(qe_scaled, columns=qe_df.columns)\n",
    "\n",
    "# Combine features and labels\n",
    "features = np.hstack((x_fp, qe_scaled_df.values))\n",
    "final_df = pd.concat([pd.DataFrame(features), df_clean['liv'].reset_index(drop=True)], axis=1)\n",
    "final_df = final_df.dropna().reset_index(drop=True)\n",
    "\n",
    "X = final_df.drop('liv', axis=1).values\n",
    "y = final_df['liv'].values\n",
    "\n",
    "# 2) Split into train/test (hold-out)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=0\n",
    ")\n",
    "\n",
    "# Save test set\n",
    "save_dir = './oob_grid_search_rf'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "torch.save({\n",
    "    'features': torch.tensor(X_test, dtype=torch.float32),\n",
    "    'labels':   torch.tensor(y_test, dtype=torch.long)\n",
    "}, os.path.join(save_dir, 'RF_test_holdout.pt'))\n",
    "\n",
    "# 3) Compute class weights on training data\n",
    "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "cw = dict(enumerate(weights))\n",
    "\n",
    "# 4) Parameter grid for Random Forest\n",
    "grid_params = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# 5) Manual grid search with OOB score\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "for params in ParameterGrid(grid_params):\n",
    "    rf = RandomForestClassifier(\n",
    "        oob_score=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight=cw,\n",
    "        **params\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    oob = rf.oob_score_\n",
    "    print(f\"Params: {params}, OOB score: {oob:.4f}\")\n",
    "    if oob > best_score:\n",
    "        best_score = oob\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best params: {best_params}, Best OOB score: {best_score:.4f}\")\n",
    "\n",
    "# 6) Retrain best model on full training set\n",
    "best_rf = RandomForestClassifier(\n",
    "    oob_score=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight=cw,\n",
    "    **best_params\n",
    ")\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# 7) Save best params and model\n",
    "joblib.dump(best_params, os.path.join(save_dir, 'RF_best_params.pkl'))\n",
    "joblib.dump(best_rf, os.path.join(save_dir, 'random_forest_oob_model.pkl'))\n",
    "\n",
    "print('OOB-based grid search completed. Test set saved at RF_test_holdout.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449e533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yunjumulti2",
   "language": "python",
   "name": "yunjumulti2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
